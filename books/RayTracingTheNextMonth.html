<meta charset="utf-8">
<!-- Markdeep: https://casual-effects.com/markdeep/ -->



                                   **Ray Tracing: The Next Month**
                                          Trevor David Black
                                                <br>
                                     Version 0.1.0-wip, 2020-XXX-XX
                                                <br>
                        Copyright 2020 Trevor David Black. All rights reserved.



Overview
====================================================================================================

Okay, so you've written a ray tracer.

In _In One Weekend_ you learned about the ray tracing paradigm and managed to render a collection of
spheres with varying material properties. You moved on to _The Next Month_ and vastly increased your
ray tracing knowledge; combining lights, quads, spheres, and volumes to produce vastly more
complicated scenes. With as much of an increase in visual fidelity that came from book one to book
two, the hope of this book is:

To set the reader on the path of writing commercially viable path tracing software.

Something needs to be made explicit: This book, _The Next Month_, is chronilogically the fourth book
in the _Ray Tracing_ series, being written after _In One Weekend_, _The Next Week_, and
_The Rest of Your Life_. However, it is the intention of the author that this book will be placed
logically as the third book in the series, falling between _The Next Week_ and
_The Rest of Your Life_. You are expected to have completed _In One Weekend_ and _The Next Week_.

This book is written in the hope that the reader will go through the chapters in order. If you find
that a specific chapter isn't particularly helpful to your interests, then you may be able to skip
it. This book is structured in blocks of chapters, where any given block will have very little
reliance on content found in a different block. You can comfortably skip over any block of chapters
without too much difficulty. The chapters would be split up this way:

Block I (Prologue)
- Multithreading
Block II
- SRT Affine Transformations
- Triangles
- Meshes
- Obj Loading
- Cleanup
Block III
- BRDF
- Diffuse Materials
- Glossy Materials
- BSSRDF
Block IV (Intermission)
- Light Paths and AOVs
Block V
- Make a Video
- Keyframes
- Shadow Rays
Block VI (Epilogue)
- Environment Map

There is a lot of ground to cover in this book, most of which still needs writing, but without any
further ado...

Happy tracing.

Of course, any bugs/complaints/feedback are very much welcome.


Multithreading
====================================================================================================

By now, you've run into the following experience:

You start up a render of a complicated scene at high sample count or high pixel dimension, or
_both_. Your computer's fan spins up to a loud degree and then you run off and get a coffee.

By the end of _The Next Week_ you were creating images where if you wanted them to have low sampling
noise you were needing to run them for 5, 10, maybe even 20 minutes. _Well_ the bad news is that
your renders are still going to take a long time. _But_, the good news is that we'll be rendering
much more complicated scenes. It's not my intention to spend too much of this time talking about
runtime performance and teaching you performance optimizations to make your renderers faster. When
you decided you wanted to ray trace you were sacrificing rendering time for visual fidelity, it just
means that you'll have a _lot_ of coffees to go grab. And, more to the point, the number and
sophistication of useful ray tracing optimizations really deserve their own book (or several).

In _The Next Week_ you learned about an extremely effective optimization in the bounding volume
hierarchy, or BVH, as it's commonly abbreviated. In the scenes that can take advantage of BVH
acceleration, the optimization changes your scene traversal from being _linear_ with scene
complexity, to being _logarithmic_ with scene complexity. This is a massive speed-up, for a scene
with 1,000,000 objects, the linear algorithm will take order 1,000,000 checks, whereas the
logarithmic algorithm will take order 1,000 checks.

However, you really won't see perfectly logarithmic complexity with any useful scene in practice,
and you probably found a couple of renders where the addition of the BVH actually **increased**
runtime. This leads us naturally to multithreading. Up to now, you've only taken advantage of a
single operating system thread, but if you've been running your renders on a computer built in the
last 15 years, you haven't been taking advantage of your computers full hardware. Any modern machine
is going to have a collection of distinct hardware cores that can each run an independent program.
These distinct hardware blocks frequently operate independently and run different programs: core 1
might be running your browser, core 2 might be running your text editor, core 3 might be running
your music player. But this only partly the truth, these hardware cores are frequently running the
same program, cores 1 through N of your machine are all probably managing your browser. For any
given program in c++ we can spin up new software threads that get mapped to a hardware core. These
hardware cores operate (largely) independently and can be made to do more work. We can spin up $N$
threads, where $N = number of hardware threads$ to speed up our render by something close to $N$.

You may note that this isn't a speedup from linear to logarithmic, but rather a speedup from linear
to linear. That may not seem as powerful, but the results can still be incredible. The author's
laptop has 6 hardware cores with 12 logical cores (more on that in a second). For a render that
takes 15 minutes while running in a single thread, the hope is that the render would take $15/6$ or
$2.5$ minutes in 6 threads.

As stated, I don't want to spend too long in this book talking about runtime performance, but some
of the additions required to get multithreading working are required for some of the more
interesting developments later on in the book. And, it's a pretty big performance win for not a lot
of code.

As for 6 hardware cores-12 logical cores statement earlier, many desktop CPUs can run multiple
software threads within one hardware thread. Intel refers to this as Hyperthreading, and AMD refers
to this as Simultaneous Multithreading (or SMT). The newer your computer, the more likely it can do
this. The underlying math part of a hardware core is shared between these 2 (frequently 2,
sometimes more) software threads, and it switches whenever the CPU needs to read something from
memory (10,000ft summary). It isn't accurate to say that a hardware core running 2 software threads
is going to see a 2x increase in the number of work it can do. But it's reasonable to expect a 1.3x
increase, so it's reasonable to expect something around $6 * 1.3 = 7.8$ increase over
singlethreaded rendering. But only if we are able to take advantage of all 12 logical cores.

If you have a comfortable and working familiarity with multithreading you can safely skip to the
last section of this chapter. The work leading up to then is mostly theory.

Averaging N Photos
----------------------------------------------------------------------------------------------------

We can start with an instructive, if limiting, exercise. Don't worry about implementing any of the
changes seen in this section, they're meant for instruction, not implementation.

If we focus our attention to the rendering loop we'll notice a few things:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    for (int j = image_height-1; j >= 0; --j) {
        std::cerr << "\rScanlines remaining: " << j << ' ' << std::flush;
        for (int i = 0; i < image_width; ++i) {
            vec3 color;
            for (int s = 0; s < samples_per_pixel; ++s) {
                auto u = (i + random_double()) / image_width;
                auto v = (j + random_double()) / image_height;
                ray r = cam.get_ray(u, v);
                color += ray_color(r, background, world, max_depth);
            }
            color.write_color(std::cout, samples_per_pixel);
        }
    }
 
    std::cerr << "\nDone.\n";
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [render-loop]: <kbd>[main.cc]</kbd> The rendering loop the program runs over]

This is all of the work of our program, there are a few things to set up like camera configuration
and scene build up, but 99.9% of our runtime exists within this code block. A few things of value:

1. It's a triply-nest loop, meaning it has 3 layers of for loops
2. We would expect that `ray_color` is where the majority of our runtime comes from
3. The number of `ray_color` invocations appears to scale with
`image_height`*`image_width`*`samples_per_pixel`

If you've played around with image dimension or pixel sampling, you'll have noticed that the program
time of your render will have scaled linearly with the number of pixels or their sample count. If we
can figure out how to split up these `ray_color` invocations into different programs or different
logical threads, then we would expect a linear speedup. This is multithreading.

The simplest way we can accomplish this is by splitting up our render. We can take our render and
split it in half: We render our scene twice, but half the sample count in each program, and then
take the average of both. This should produce an image with the image dimensions and samples per
pixel of the original image, but will have run in two different logical threads, whereby taking
better advantage of our underlying hardware.

We'll start this example at the end of _The Next Week_. Taking the final scene of that book, we'll
render at 32 samples per pixel as our baseline:

  <div class="render">

  ![The Next Week final scene in 32 spp](../images/img.book2-final_32spp.png)

  </div>

With that render completed, we will take advantage of our operating system's threads by spinning up
two instances of the render. We'll start up one render at 16 samples per pixel, and then start up
another render at 16 samples per pixel. If our operating system has threads available, it should
run both of our renders seperately, and we should see both take about half as long as the 32 samples
per pixel run from earlier.

The first 16spp render: 
  <div class="render">

  ![The Next Week final scene in 16 spp (first render)](../images/img.book2-final_16spp.png)

  </div>

And here is the second 16spp render:
  <div class="render">

  ![The Next Week final scene in 16 spp (second render)](../images/img.book2-final_16spp.png)

  </div>

Both of our outputted images were created in the ppm file format. We need to take the average of
these two photos to approximate the 32 sample per pixel image. We can either write a ppm loader
or take advantage of existing tools. Any photo editing software like Photoshop, GIMP, Krita, etc.
will be able to combine two photos. You can write a ppm loader if you're interested, but I will
just be combining these in a photo editor. If you're unsure of how to do this, don't worry, you
won't need to explicitly combine the images to follow along.

When we use a photo editor to combine our two 16spp images we get:
  <div class="render">

  ![The Next Week final scene in 16 spp (second render)](../images/img.book2-final_16spp.png)

  </div>

Which, does not look like 32 samples per pixel, it doesn't even look better than 16 samples per
pixel. What is going on here?

Well, all three images: the first 16spp render, the second 16spp render, and the combined 32spp
render are all perfectly identical. They are pixel perfect copies of one another. The two 16spp
renders are themselves identical, and the average of the two gives us more of the same.

This leads us to wonder why the original 16 samples per pixel are identical. When we wrote the
rendering loop, we made sure to randomize the location of rays to remove aliasing:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    for (int j = image_height-1; j >= 0; --j) {
        std::cerr << "\rScanlines remaining: " << j << ' ' << std::flush;
        for (int i = 0; i < image_width; ++i) {
            vec3 color;
            for (int s = 0; s < samples_per_pixel; ++s) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
                auto u = (i + random_double()) / image_width;
                auto v = (j + random_double()) / image_height;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
                ray r = cam.get_ray(u, v);
                color += ray_color(r, background, world, max_depth);
            }
            color.write_color(std::cout, samples_per_pixel);
        }
    }
 
    std::cerr << "\nDone.\n";
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [render-loop-randomness]: <kbd>[main.cc]</kbd> Sources of random in the rendering loop]

The `u` and `v` coordinates of the ray within the image should be different between different
renders. If the `u` and `v` values for one ray are the same as for another ray, we might be
sampling the same part of the scene and we wouldn't be getting any new information. Let's dig into
our `random_double` function:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    inline double random_double() {
        return rand() / (RAND_MAX + 1.0);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [random_double]: <kbd>[rtweekend.h]</kbd> The random_double function]

Okay, `random_double` calls into `rand`. `rand` is a c++ function found in `<cstlib>` that returns
pseudo-random number betwen `0` and `RAND_MAX` using a seed. A couple of important facts in that
sentence. The first thing is that `rand` is not a truly random number generator, calls to `rand` are
not truly random, rather, calls to `rand` follow a deterministic pattern. This is the reason that
different calls to the program produce identical results, any sources of random will be the same for
both runs. So, even though we were hoping to get different data about our scene, we receive the same
data. So much for random. It's not all problematic, though. What we can do is change what the
pattern is.

For any given seed entered into a pseudo-random number generator, that generator will always produce
the same string of "random" numbers. If we change the seed for that random generator it will produce
a different string of "random" numbers. For the function `rand` there exists the function `srand`
that will change the seed that `rand` calls into. All we need to do is call `srand` on `main`:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #include <iostream>
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    #include <ctime>
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    ...
    int main() {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        srand(time(NULL));
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
        const int image_width = 768;
        const int image_height = 768;
        const auto aspect_ratio = double(image_width) / image_height;

        hittable_list world;

        int samples_per_pixel = 16;
        int max_depth = 50;

        vec3 lookfrom;
        vec3 lookat;
        vec3 vup(0,1,0);
        auto vfov = 40.0;
        auto aperture = 0.0;
        auto dist_to_focus = 10.0;
        vec3 background(0,0,0);

        ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [changing-rand-seed]: <kbd>[main.cc]</kbd> Changing the seed for rand on program start]

The argument to `srand` just tells `srand` to set the seed to the current time. Now when we call
`rand` we'll get different random numbers, and we should receive different images from our renders.
Indeed, we do:

  <div class="render">

  ![The Next Week final scene in 16 spp (first seed)](../images/img.book2-final_new-seed-1_16spp.png)

  </div>

  <div class="render">

  ![The Next Week final scene in 16 spp (second seed)](../images/img.book2-final_new-seed-2_16spp.png)

  </div>


<!-- Fix perlin bug in final scene --> 

<!-- rerender final scene again with correct earthmap --> 

<!-- "Show off new averaging"--> 

<!-- "Explain why it fails for random parts of our scene"--> 

<!-- "Say that we can map random parts of the scene to a constant seed"-->

The lesson here is that if you have multiple runs of a render you need to be cognizant of where your
random numbers are coming from, and where they are going. Something that hasn't been mentioned until
now needs to be brought up. It's perhaps a bit strange that `rand` starts with the seed every time
until the programmer explicitly changes it. For a function that is producing random numbers, a naive
assumption would be that `rand` should be producing _different_ random numbers each time, and so
**should** be starting with a different seed every time.

However, this isn't the case in practice, and `rand` always starts with a specific seed. Indeed,
this is the default, as it is desirable for a random number generator to have a specific seed.
Between different runs of our renderer, as we increase samples per pixel or make edits to our code,
we want code that is functionally the same to produce an identical image. If accidentally introduce
a bug to our code, we want our output to change, indeed we only want our output to change when our
code has become functionally different. If our random number generator (`rand`) produced different
images between one run and the next, we would have a much more difficult time knowing if the changes
are due to `rand` or are due to a bug we accidentally introduced.


Spinning Up C++ Threads
----------------------------------------------------------------------------------------------------

Averaging multiple photos is a viable option and can be a quick way to take advantage of the
parallel nature of your hardware. But there is a long list of things to consider when doing it
accurately, the biggest thing being your random number generator, but your renderer's
post-processing also needs to be taken into account. If your post-processing step (gamma curve) is
nonlinear, as the gamma curve almost always is, you cannot add the results of two gamma corrected
outputs and get an accurate result. There are other considerations that we won't get into.

Let's return to our rendering loop:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    for (int j = image_height-1; j >= 0; --j) {
        std::cerr << "\rScanlines remaining: " << j << ' ' << std::flush;
        for (int i = 0; i < image_width; ++i) {
            vec3 color;
            for (int s = 0; s < samples_per_pixel; ++s) {
                auto u = (i + random_double()) / image_width;
                auto v = (j + random_double()) / image_height;
                ray r = cam.get_ray(u, v);
                color += ray_color(r, background, world, max_depth);
            }
            color.write_color(std::cout, samples_per_pixel);
        }
    }
 
    std::cerr << "\nDone.\n";
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [render-loop-return]: <kbd>[main.cc]</kbd> A return to the rendering loop]

Our ultimate goal is to figure out a way to split up the work being done in this block of code. We
know that our hardware can run multiple hardware threads at once, and that our operating system
supports multiple programs by controlling how we match different programs to different hardware
cores. Another option exists for us here. We can spin up a single program (a single render) and then
use some of C++'s existing functionality to add additional threads to this program.

From C++11 onward, C++ now has `std::thread` which can be called from within a C++ program to create
and manage an operating system thread. Our C++ block tells the operating system that it has another
thread, and then the operating system manages how that additional thread matches to the underlying
hardware. We don't fully need to know how this works, but it is important to know that our program
can choose to create more program threads than their are logical cores for. The operating system
will manage this just fine. For my 6 core, 12 thread laptop, it's fine to spin up 1000s of threads
if I want to. So, let's do that.

We start by adding `std::thread` to the rendering loop:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    #include <iostream>
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    #include <thread>
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    ...
    int main() {
    ...
    for (int j = image_height-1; j >= 0; --j) {
        std::cerr << "\rScanlines remaining: " << j << ' ' << std::flush;
        for (int i = 0; i < image_width; ++i) {
            vec3 color;
            for (int s = 0; s < samples_per_pixel; ++s) {
                auto u = (i + random_double()) / image_width;
                auto v = (j + random_double()) / image_height;
                ray r = cam.get_ray(u, v);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
                vec3 thread_color;
                std::thread t0(ray_color, r, background, world, max_depth, &thread_color);
                t0.join();
                color += thread_color;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            }
            color.write_color(std::cout, samples_per_pixel);
        }
    }
 
    std::cerr << "\nDone.\n";
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [adding-threads]: <kbd>[main.cc]</kbd> Adding threads to the render]

Lots to cover with this change. We've added a new default `vec3` called thread_color. We then
call into a rather complicated constructor for the `std::thread` type. We then call `join` on our
newly constructed thread, and then add `thread_color` back into `color`. To start, the `join`
call is necessary for two reasons. First, the main thread must call into `join` to wait for results
from that thread. The main thread must ask any constructed threads if they've completed their work.
The `join` function tells the main thread to wait for the `t0` thread to finish all of it's work.

The biggest change to the rendering loop is the construction of a `std::thread` called
`t0`. When a thread is initialized it is passed a function as it's first parameter, in this case
that function is `ray_color`, while the remaining arguments to the initialization are the arguments
to the function argument. So, `r, background, world, max_depth, &thread_color` are the arguments
we're passing to `ray_color`. We didn't previously have a `&thread_color` as a function argument to
`ray_color`. We need to make this change because `std::thread` does not have a mechanism to capture
the return values from it's function invocation. If we want to grab the output from `ray_color` we
need to turn `ray_color` into a return type `void` and pass it's return value back through a
pointer:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
    void ray_color(
        const ray& r, const vec3& background, const hittable& world, int depth, vec3* color) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        hit_record rec;

        // If we've exceeded the ray bounce limit, no more light is gathered.
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        if (depth <= 0) {
            *color = vec3(0,0,0);
            return;
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        // If the ray hits nothing, return the background color.
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        if (!world.hit(r, 0.001, infinity, rec)) {
            *color = background;
            return;
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        ray scattered;
        vec3 attenuation;
        vec3 emitted = rec.mat_ptr->emitted(rec.u, rec.v, rec.p);

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        if (!rec.mat_ptr->scatter(r, rec, attenuation, scattered)){
            *color = emitted;
            return;
        }

        *color = emitted + attenuation * ray_color(scattered, background, world, depth-1);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [adding-threads]: <kbd>[main.cc]</kbd> Adding threads to the render]

After this change, the rendering loop will produce the same result as before:

  <div class="render">

  ![The Next Week final scene in 32 spp](../images/img.book2-final_32spp.png)

  </div>

But, it wasn't faster **at all**. In fact, it was _a lot_ slower. I wouldn't be surprised if you
gave up partway through the render. What gives?

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    for (int j = image_height-1; j >= 0; --j) {
        std::cerr << "\rScanlines remaining: " << j << ' ' << std::flush;
        for (int i = 0; i < image_width; ++i) {
            vec3 color;
            for (int s = 0; s < samples_per_pixel; ++s) {
                auto u = (i + random_double()) / image_width;
                auto v = (j + random_double()) / image_height;
                ray r = cam.get_ray(u, v);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
                vec3 thread_color;
                std::thread t0(ray_color, r, background, world, max_depth, &thread_color);
                t0.join();
                color += thread_color;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            }
            color.write_color(std::cout, samples_per_pixel);
        }
    }
 
    std::cerr << "\nDone.\n";
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [thread-inspection]: <kbd>[main.cc]</kbd> Highlighting the threading changes]


Let's inspect what we've asked our code to do.

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    for every ROW
        for every PIXEL in ROW
            for every SAMPLE per PIXEL
                get RANDOM-RAY into PIXEL
                start new THREAD for RANDOM-RAY
                wait for new THREAD to stop
                add results to PIXEL
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [render-loop-pseudo]: The pseudo code for our modified rendering loop]

We're spinning up a new thread and immediately waiting for it finish. We spin up one thread at a
time and then wait for one thread at a time. We're never running multiple threads, so this is only
as fast as doing the single-threaded render loop. Worse, we have to eat the cost of talking with the
operating system to spin up new threads and other cross-thread communication (like `join`). So this
can only be as fast as the single-threaded run, and will be significantly worse in practice. We'll
need to think of something a bit more actionable.

The loop as written only spins up a single thread at a time, and then waits for that single thread
to finish. Maybe we'll get a speedup if we can figure out a way to spin up multiple threads at a
time, and then wait for all of those to finish:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    for all THREADs
        start new THREAD

    for all THREADs
        wait for THREAD to stop

    combine results
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [multiple-threads]: The pseudo code for spinning up multiple threads]

Let's turn that into c++ code:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    for (int j = image_height-1; j >= 0; --j) {
        std::cerr << "\rScanlines remaining: " << j << ' ' << std::flush;
        for (int i = 0; i < image_width; ++i) {
            vec3 color;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
            std::thread sample_threads[samples_per_pixel];
            vec3 thread_colors[samples_per_pixel];

            for (int s = 0; s < samples_per_pixel; ++s) {
                auto u = (i + random_double()) / image_width;
                auto v = (j + random_double()) / image_height;
                ray r = cam.get_ray(u, v);
                sample_threads[s] = std::thread(
                    ray_color, r, background, world, max_depth, &thread_colors, s);
            }

            for (int s = 0; s < samples_per_pixel; ++s) {
                sample_threads[s].join();
                color += thread_colors[s];
            }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
            
            color.write_color(std::cout, samples_per_pixel);
        }
    }
 
    std::cerr << "\nDone.\n";
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [threads-per-sample]: <kbd>[main.cc]</kbd> Spin up threads across sampling of a pixel]

We spin up multiple threads equal to the number of `samples_per_pixel` , and _then_ wait for them to
finish so that we can take their sum.

We added the `s` index to the `ray_color` function:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    void ray_color(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        const ray& r, const vec3& background, const hittable& world,
        int depth, vec3* color, int thread_id) {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        hit_record rec;

        // If we've exceeded the ray bounce limit, no more light is gathered.
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        if (depth <= 0) {
            color[thread_id] = vec3(0,0,0);
            return;
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        // If the ray hits nothing, return the background color.
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        if (!world.hit(r, 0.001, infinity, rec)) {
            color[thread_id] = background;
            return;
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++

        ray scattered;
        vec3 attenuation;
        vec3 emitted = rec.mat_ptr->emitted(rec.u, rec.v, rec.p);

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ highlight
        if (!rec.mat_ptr->scatter(r, rec, attenuation, scattered)){
            color[thread_id] = emitted;
            return;
        }

        color[thread_id] = emitted + attenuation * ray_color(scattered, background, world, depth-1);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [adding-threads]: <kbd>[main.cc]</kbd> Adding threads to the render]


<!-- Discuss race conditions --> 

<!-- Implement vector of pixel data --> 


N Threads for the Whole Render
----------------------------------------------------------------------------------------------------




<!-- Markdeep: https://casual-effects.com/markdeep/ -->
<link rel='stylesheet' href='../style/book.css'>
<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script src="markdeep.min.js"></script>
<script src="https://casual-effects.com/markdeep/latest/markdeep.min.js"></script>
<script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
